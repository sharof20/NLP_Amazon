{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13272048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External libraries\n",
    "import pandas as pd\n",
    "import inflect\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Input,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    LSTM,\n",
    "    Bidirectional,\n",
    "    Embedding\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# The project's modules\n",
    "from data_collection.util_collect import data_collection\n",
    "from data_management.util_cleaning import data_cleaning\n",
    "from data_management.util_data_prep_for_modelling import (\n",
    "    dataframe_summary,\n",
    "    plot_review_counts,\n",
    "    process_ratings,\n",
    "    undersample_majority,\n",
    "    add_word_count,\n",
    "    plot_and_save_avg_words_vs_rating,\n",
    "    text_Preprocessing,\n",
    "    add_word_count_after_preprocessing\n",
    ")\n",
    "from nlp_model_functions.util_lstm_glove import (\n",
    "    separate_features_and_target,\n",
    "    tokenize_reviews,\n",
    "    pad_text_sequences,\n",
    "    download_glove_embeddings,\n",
    "    load_glove_embeddings,\n",
    "    create_embedding_matrix,\n",
    "    evaluate_model_performance,\n",
    "    lstm_plot_confusion_matrix,\n",
    "    calculate_predicted_and_actual,\n",
    "    plot_loss,\n",
    "    make_rounded_predictions\n",
    ")\n",
    "from nlp_model_functions.util_BERT import (\n",
    "    split_data,\n",
    "    tokenize_texts,\n",
    "    get_dataset,\n",
    "    get_model,\n",
    "    compile_and_train,\n",
    "    evaluate_metrics,\n",
    "    predict_with_bert,\n",
    "    plot_confusion_matrix,\n",
    "    plot_and_save_loss\n",
    ")\n",
    "\n",
    "# Special utility imports (if needed in a non-Colab environment, you might not need these)\n",
    "# from google.colab import files\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Set global settings\n",
    "%matplotlib inline\n",
    "p = inflect.engine()\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c0780a",
   "metadata": {},
   "source": [
    "## data_collection Function\n",
    "\n",
    "**Purpose:**  \n",
    "This function initiates the process of scraping Amazon product reviews by tying all the smaller functions together.\n",
    "\n",
    "### Overview:\n",
    "\n",
    "1. Initializes the Selenium driver and navigates to Amazon's website.\n",
    "2. Performs a search on Amazon using the provided keyword.\n",
    "3. Collects product links based on the search results up to the specified number of pages.\n",
    "4. Scrapes reviews from the collected product links.\n",
    "5. Exports the scraped reviews to a specified CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5881dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can then call this function with the search term, maximum pages, and filename\n",
    "# Kindly note that the data collection function takes a long time to collect Amazon products' reviews\n",
    "# So that here the function is commented out\n",
    "#data_collection(\"home electronics\", max_pages=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786be4f4",
   "metadata": {},
   "source": [
    "## data_cleaning Function\n",
    "\n",
    "**Purpose:**  \n",
    "Performs end-to-end data cleaning and preparation on multiple CSV files from a specified directory.\n",
    "\n",
    "### Overview:\n",
    "\n",
    "1. Merges multiple CSV files from a directory into a single DataFrame.\n",
    "2. Processes the merged DataFrame (reordering columns, shuffling rows).\n",
    "3. Removes duplicates and handles missing values.\n",
    "4. Refines ratings (extraction and filtering).\n",
    "5. Cleans the review texts.\n",
    "6. Filters out anomalies in reviews.\n",
    "7. Separates English and non-English reviews.\n",
    "8. Translates non-English reviews to English. (NOTE: RUNNING TAKES LONGER TIME)\n",
    "9. Saves the cleaned DataFrame to a specified CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7098dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the directory containing the original, collected raw data.\n",
    "input_directory = 'data/data_sample'\n",
    "\n",
    "# Specify the path where the cleaned and processed CSV file will be saved.\n",
    "output_file = 'data/cleaned_data/test_last_cleaned_output.csv'\n",
    "\n",
    "# Call the data_cleaning function to perform end-to-end data cleaning.\n",
    "# The function will read all CSV files from 'input_directory', process them, and save the cleaned data to 'output_file'.\n",
    "data_cleaning(input_directory, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf02669",
   "metadata": {},
   "source": [
    "## Data Processing Workflow for the NLP models\n",
    "\n",
    "### 1. Load and Review Data:\n",
    "Load the cleaned data from a CSV file and review its structure and content.\n",
    "### 2. Initial Data Summary:\n",
    "Generate a summary of the dataframe.\n",
    "### 3. Plotting Review Counts:\n",
    "Plot the distribution of review counts across different ratings, showcasing potential class imbalance.\n",
    "### 4. Process Ratings:\n",
    "Process and  transform 5 and 4 scores into 1 (positive), 1 and 2 into (negative) in the ratings column.\n",
    "### 5. Balance Dataset:\n",
    "Address the class imbalance issue by undersampling majority classes.\n",
    "### 6. Re-plot Review Counts:\n",
    "Showcase the new distribution of review counts after addressing class imbalance.\n",
    "### 7. Word Count:\n",
    "Calculate and print the maximum word count across reviews. Also, visualize the average word count vs. rating.\n",
    "### 8. Text Preprocessing: text_Preprocessing Function\n",
    "**Purpose:**  \n",
    "To preprocess a list of text strings for NLP tasks.\n",
    "#### Steps:\n",
    "1. **Lowercasing:** Convert each string to lowercase.\n",
    "2. **Removing emails:** Eliminate email addresses from the strings.\n",
    "3. **Removing digits:** Get rid of any numerical characters in the strings.\n",
    "4. **Removing special characters:** Remove characters that are not alphabets, numbers, or whitespaces.\n",
    "5. **Removing extra spaces:** Trim any leading or trailing spaces.\n",
    "6. **Removing emojis:** Remove any emojis present in the string.\n",
    "7. **Stopwords removal:** Eliminate common words (e.g., \"and\", \"the\", \"is\") that typically don't contain significant meaning.\n",
    "8. **Lemmatization:** Convert words to their base or dictionary form (e.g., \"running\" -> \"run\").\n",
    "### 9. Word Count Post-Processing:\n",
    "Calculate word count again after preprocessing.\n",
    "### 10. Last checkpoint for spaces:\n",
    "Identify and remove rows where the 'Reviews' or 'Rating' columns contain only spaces.\n",
    "### 11. Save Data:\n",
    "Store the processed DataFrame in a new CSV file, ready for modelling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf822d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned dataset\n",
    "data = pd.read_csv(\"data\\cleaned_data\\last_cleaned_output.csv\")\n",
    "df = data\n",
    "\n",
    "# Display a summary of the dataframe\n",
    "dataframe_summary(df)\n",
    "\n",
    "# Plot distribution of review counts before balancing\n",
    "plot_review_counts(df, save_path='data_management/plots', file_name='imbalanced_ratings.png')\n",
    "\n",
    "# Process ratings in the dataframe\n",
    "df = process_ratings(df)\n",
    "\n",
    "# Balance the dataset by undersampling the majority class\n",
    "df = undersample_majority(df)\n",
    "\n",
    "# Plot distribution of review counts after balancing\n",
    "plot_review_counts(df, save_path='data_management/plots', file_name='balanced_ratings.png')\n",
    "\n",
    "# Add a column with word counts and get the maximum word count\n",
    "df, max_count = add_word_count(df)\n",
    "print(f\"Maximum word count in the DataFrame: {max_count}\")\n",
    "\n",
    "# Plot average number of words vs. ratings\n",
    "plot_and_save_avg_words_vs_rating(df, save_path='data_management/plots', filename='average_number_words.png')\n",
    "\n",
    "# Preprocess the 'Reviews' column for textual data\n",
    "df['Reviews'] = text_Preprocessing(df['Reviews'])\n",
    "\n",
    "# Add a column with word counts post-text preprocessing\n",
    "df = add_word_count_after_preprocessing(df, 'Reviews')\n",
    "\n",
    "# Convert the 'Reviews' column to string type just to ensure it's string\n",
    "df['Reviews'] = df['Reviews'].astype(str)\n",
    "\n",
    "# Identify rows where 'Reviews' column is only spaces\n",
    "rows_with_spaces = df[df['Reviews'].str.strip().str.len() == 0]\n",
    "\n",
    "# Remove rows containing only spaces in the 'Reviews' column\n",
    "df = df.drop(rows_with_spaces.index)\n",
    "df.head()\n",
    "# Save the processed DataFrame to a new CSV file\n",
    "df.to_csv('data/data_for_modelling/ready_data_for_modelling.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594749fc",
   "metadata": {
    "id": "594749fc"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data_for_modelling/ready_data_for_modelling.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e55a41d",
   "metadata": {
    "id": "7e55a41d"
   },
   "source": [
    "## Splitting the Data\n",
    "\n",
    "Once our data is ready, the next step is to split it into training and testing sets. This allows us to train our models on one subset and validate its performance on another unseen subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zukqDFIWmIgX",
   "metadata": {
    "id": "zukqDFIWmIgX"
   },
   "outputs": [],
   "source": [
    "train,test=train_test_split(df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3d622c",
   "metadata": {},
   "source": [
    "## Checking the Shape of the Datasets\n",
    "\n",
    "It's essential to know the size of the training and testing sets after splitting. This ensures we have a sufficient amount of data for both training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae61712",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ae61712",
    "outputId": "c8cf1454-caa4-48a2-9870-8d7905529d8f"
   },
   "outputs": [],
   "source": [
    "# Displaying the shape of training set\n",
    "print(train.shape)\n",
    "\n",
    "# Displaying the shape of test set\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05172e09",
   "metadata": {},
   "source": [
    "## The `separate_features_and_target` Function\n",
    "\n",
    "Let's apply the `separate_features_and_target` function to our dataset.\n",
    "\n",
    "### Step 1: Separate Data\n",
    "\n",
    "We are separating our train and test data into feature variables (X_train and X_test) and target variables (y_train and y_test), with 'Rating' being the target column.\n",
    "\n",
    "### Step 2: Displaying the Separated Data\n",
    "To ensure the data has been separated correctly, let's display the initial rows of each set.\n",
    "\n",
    "From the printed output, we can see the top rows of the feature datasets (X_train and X_test) and the corresponding target values (y_train and y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iDOWgONO6roD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDOWgONO6roD",
    "outputId": "b1fa62a1-7b5d-4486-fb58-7d755237dbe3"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = separate_features_and_target(train, test, 'Rating')\n",
    "\n",
    "# Displaying the separated features and target variables\n",
    "print(\"X_train:\")\n",
    "print(X_train.head())\n",
    "print(\"\\ny_train:\")\n",
    "print(y_train.head())\n",
    "print(\"\\nX_test:\")\n",
    "print(X_test.head())\n",
    "print(\"\\ny_test:\")\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f81c1",
   "metadata": {},
   "source": [
    "## Setting Up the Tokenizer and Applying Tokenization\n",
    "\n",
    "To convert the reviews into tokenized sequences, we need to set up and fit a tokenizer. This will enable the model to understand and process the text data in our reviews.\n",
    "\n",
    "### Step 1: Initializing the Tokenizer\n",
    "\n",
    "We initialize a Keras tokenizer object.\n",
    "The num_words argument restricts the tokenizer to only consider the top 15,000 most frequent words in the dataset.\n",
    "\n",
    "### Step 2: Fitting the Tokenizer on the Training Data\n",
    "\n",
    "The fit_on_texts method allows the tokenizer to learn the vocabulary present in our X_train['Reviews'] data.\n",
    "\n",
    "### Step 3: Tokenizing the Reviews\n",
    "\n",
    "We use our previously defined tokenize_reviews function to tokenize the \"Reviews\" column in both the training and testing datasets.\n",
    "The tokenized sequences are stored in the \"text_tokenizer\" column in each dataset.\n",
    "By the end of these steps, our datasets are prepared with tokenized sequences that are ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9GNA0BVJJokl",
   "metadata": {
    "id": "9GNA0BVJJokl"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train['Reviews'])\n",
    "X_train, X_test = tokenize_reviews(X_train, X_test, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ac3db",
   "metadata": {},
   "source": [
    "## Applying Padding and Truncation to our Data\n",
    "\n",
    "Once we have defined the function to pad and truncate our sequences, the next step is to apply this transformation to our training and testing datasets. \n",
    "\n",
    "### Using the `pad_text_sequences` Function:\n",
    "\n",
    "**By calling this function**:\n",
    "\n",
    "X_train and X_test, which contain the tokenized sequences in the 'text_tokenizer' column, are transformed.\n",
    "The sequences are padded (or truncated) to have a uniform length of 1000 tokens, as set by the default maxlen parameter in our function.\n",
    "The resulting padded sequences for the training data are stored in X_train_pad.\n",
    "The resulting padded sequences for the testing data are stored in X_test_pad.\n",
    "Now, both X_train_pad and X_test_pad are ready to be used as input for neural network models that require fixed-length sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evP1dg4GCsEU",
   "metadata": {
    "id": "evP1dg4GCsEU"
   },
   "outputs": [],
   "source": [
    "X_train_pad, X_test_pad = pad_text_sequences(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11aa4d8",
   "metadata": {},
   "source": [
    "## Downloading GloVe Embeddings\n",
    "\n",
    "[GloVe (Global Vectors for Word Representation)](https://nlp.stanford.edu/projects/glove/) is an unsupervised learning algorithm developed by Stanford for generating word embeddings. These embeddings can be used to improve the performance of NLP models, especially for our text classification task. We will discuss Glove vectors in details later in the model construction.\n",
    "\n",
    "### Setting up the GloVe Download:\n",
    "\n",
    "**URL and Local Storage Definitions**:\n",
    "   - `GLOVE_URL`: The online URL from Stanford's site where the GloVe embeddings (specifically the Twitter dataset version) can be accessed.\n",
    "   - `GLOVE_DIR`: The local directory where the downloaded embeddings should be stored.\n",
    "\n",
    "**File Download**:\n",
    "We first check if the GloVe embeddings are already downloaded to avoid re-downloading.\n",
    "If the embeddings are not found, we download them from the given URL and save them in the specified directory.\n",
    "\n",
    "By following these steps, we ensure efficient retrieval of the GloVe embeddings, which can significantly enhance the quality of text representations in our subsequent models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c7d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL and the local path where the file should be saved\n",
    "GLOVE_URL = 'https://nlp.stanford.edu/data/glove.twitter.27B.zip'\n",
    "GLOVE_DIR = 'data/glove'\n",
    "\n",
    "# Call the function\n",
    "download_glove_embeddings(GLOVE_URL, GLOVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37728e",
   "metadata": {},
   "source": [
    "## Loading and Inspecting the GloVe Embeddings\n",
    "\n",
    "We set glove_zip_path to the location where our GloVe ZIP file is stored. We then call our previously defined load_glove_embeddings function to load the word vectors. Furthemore, we print the total number of unique words present in the loaded GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a3a230",
   "metadata": {
    "id": "41a3a230",
    "outputId": "750a8de2-cf64-4418-b399-5cfd56286f47"
   },
   "outputs": [],
   "source": [
    "glove_zip_path = \"data/glove/glove.twitter.27B.zip\"\n",
    "glove, glove_words = load_glove_embeddings(glove_zip_path)\n",
    "# Displaying some information about the loaded embeddings\n",
    "print(f\"Number of words in GloVe: {len(glove_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50146071",
   "metadata": {},
   "source": [
    "## Creating the Embedding Matrix\n",
    "\n",
    "To leverage the power of pre-trained GloVe embeddings for our model, we need an embedding matrix. This matrix serves as a bridge between our dataset's vocabulary and GloVe's pre-trained vectors.\n",
    "\n",
    "### Function: create_embedding_matrix\n",
    "\n",
    "The dimension of the GloVe word vectors, with a default value of 100.\n",
    "The funtion returns a NumPy array that represents the embedding matrix suitable for use in a Keras Embedding layer.\n",
    "\n",
    "#### How our embedding matrix works:\n",
    "\n",
    "**Determine Vocabulary Size**: The vocabulary size is obtained from the tokenizer's word index.\n",
    "**Initialize an Embedding Matrix**: A matrix of zeros with a shape (max_vocabulary+1, embedding_dim). The extra \"+1\" accounts for out-of-vocabulary words or padding tokens.\n",
    "**Populate the Matrix**: To fill in the embedding matrix we iterate over each word in the tokenizer's word index. For each word, we check if a pre-trained GloVe vector exists. If it exists, the corresponding row in the embedding matrix is populated with the GloVe vector. \n",
    "\n",
    "By the end of this process, we'll have an embedding matrix where each row corresponds to the vector representation of a word in our dataset's vocabulary. This matrix can be directly used in our neural network's embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dEXGy8GFHCIM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dEXGy8GFHCIM",
    "outputId": "0fef8725-31d9-467d-ac56-3f274c3e03ad"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = create_embedding_matrix(tokenizer, glove_words, glove)\n",
    "# Displaying the shape of embedding matrix information about the created embedding matrix\n",
    "print(f\"Shape of embedding matrix: {embedding_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e8b63c",
   "metadata": {},
   "source": [
    "### Variables Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b10418a",
   "metadata": {
    "id": "9b10418a"
   },
   "outputs": [],
   "source": [
    "X_train = X_train_pad\n",
    "X_test = X_test_pad\n",
    "Y_train = y_train\n",
    "Y_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a7021",
   "metadata": {},
   "source": [
    "The model is for text classification based on Amazon reviews. It uses pre-trained word embeddings combined with LSTM layers.\n",
    "\n",
    "### Function definition:\n",
    "```python\n",
    "def LSTM_Glove_model(embedding_matrix, max_vocabulary):\n",
    "```\n",
    "\n",
    "- The function is named `create_review_model`.\n",
    "- It takes two parameters:\n",
    "  - `embedding_matrix`: This is a pre-trained word embedding matrix.\n",
    "  - `max_vocabulary`: This is the maximum number of unique words in the vocabulary.\n",
    "\n",
    "### Input layer:\n",
    "```python\n",
    "review = Input(shape=(1000,), name='review_input')\n",
    "```\n",
    "\n",
    "- This specifies the input to the model. Each review is represented as a sequence of 1000 tokens. These tokens will typically be integer values, each corresponding to a word in a vocabulary.\n",
    "\n",
    "### Embedding layer:\n",
    "```python\n",
    "X = Embedding(output_dim=100,\n",
    "              input_dim=max_vocabulary + 1,\n",
    "              input_length=1000,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False)(review)\n",
    "```\n",
    "\n",
    "- The layer converts integer token values into dense vectors of fixed size.\n",
    "- `output_dim=100`: Each word (token) is represented as a 100-dimensional vector.\n",
    "- `input_dim=max_vocabulary + 1`: The size of the vocabulary. We add 1 to account for the padding token.\n",
    "- `input_length=1000`: This sets the sequence length.\n",
    "- `weights=[embedding_matrix]`: This initializes the embedding layer with the pre-trained word vectors provided by `embedding_matrix`.\n",
    "- `trainable=False`: This means the word embeddings will not be updated during training.\n",
    "\n",
    "### Bidirectional LSTM layer:\n",
    "```python\n",
    "lstm_review = Bidirectional(LSTM(100))(X)\n",
    "```\n",
    "\n",
    "- This layer uses LSTM (Long Short Term Memory) units, which are a type of Recurrent Neural Network (RNN) that can remember past information.\n",
    "- `Bidirectional` means that the LSTM will process the sequence from both directions (start-to-end and end-to-start). This often helps in capturing patterns effectively.\n",
    "- It uses 100 LSTM units.\n",
    "\n",
    "### Dropout layer:\n",
    "```python\n",
    "model = Dropout(0.5)(lstm_review)\n",
    "```\n",
    "\n",
    "- This layer randomly sets half (50%) of the input units to 0 at each update during training time. This helps in preventing overfitting.\n",
    "\n",
    "### Flatten layer:\n",
    "```python\n",
    "model = Flatten()(model)\n",
    "```\n",
    "\n",
    "- After LSTM, the data might have two dimensions (one for sequence and one for features). This layer flattens the output to prepare it for the Dense layers that follow.\n",
    "\n",
    "### Dense layers:\n",
    "```python\n",
    "model = Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(0.001))(model)\n",
    "model = Dense(8, activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(0.001))(model)\n",
    "```\n",
    "\n",
    "- These are fully connected neural network layers.\n",
    "- The first Dense layer has 64 units and the second has 8 units.\n",
    "- They both use the ReLU activation function.\n",
    "- The `kernel_initializer=\"he_normal\"` means that the initial weights of these layers are drawn from a He-normal distribution, which is commonly used with ReLU activations.\n",
    "- `kernel_regularizer=l2(0.001)`: This applies L2 regularization to the weights of the neurons in these layers, helping to prevent overfitting.\n",
    "\n",
    "### Output layer:\n",
    "```python\n",
    "output = Dense(1, activation='sigmoid', name='output')(model)\n",
    "```\n",
    "\n",
    "- This is the final layer, and it's designed for binary classification. It has a single neuron with a sigmoid activation function, which will output values between 0 and 1.\n",
    "\n",
    "### Model Compilation:\n",
    "```python\n",
    "model = Model(inputs=[review], outputs=[output])\n",
    "```\n",
    "\n",
    "- This line consolidates all the layers we defined into a Keras Model.\n",
    "\n",
    "### Summary:\n",
    "```python\n",
    "print(model.summary())\n",
    "```\n",
    "\n",
    "- This prints a summary of the model's architecture.\n",
    "\n",
    "### Return:\n",
    "Finally, the function returns the constructed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99_AodJol_Zi",
   "metadata": {
    "id": "99_AodJol_Zi"
   },
   "outputs": [],
   "source": [
    "def LSTM_Glove_model(embedding_matrix, max_vocabulary):\n",
    "    \"\"\"\n",
    "    Creates a Keras model for text classification based on reviews.\n",
    "\n",
    "    Parameters:\n",
    "        embedding_matrix (ndarray): Pre-trained embedding weights.\n",
    "        max_vocabulary (int): Maximum number of unique words in the vocabulary.\n",
    "\n",
    "    Returns:\n",
    "        model (Model): The Keras Model object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the shape of the input for the review (1000 tokens)\n",
    "    review = Input(shape=(1000,), name='review_input')\n",
    "\n",
    "    # Embedding layer\n",
    "    # Uses pre-trained weights (embedding_matrix) and sets it to non-trainable\n",
    "    X = Embedding(output_dim=100,\n",
    "                  input_dim=max_vocabulary + 1,\n",
    "                  input_length=1000,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=False)(review)\n",
    "\n",
    "    # LSTM layer\n",
    "    # Uses Bidirectional LSTM with 100 units\n",
    "    lstm_review = Bidirectional(LSTM(100))(X)\n",
    "\n",
    "    # Dropout layer to reduce overfitting\n",
    "    model = Dropout(0.5)(lstm_review)\n",
    "\n",
    "    # Flatten layer to prepare for dense layers\n",
    "    model = Flatten()(model)\n",
    "\n",
    "    # First Dense layer with 64 units, ReLU activation, and L2 regularization\n",
    "    model = Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(0.001))(model)\n",
    "\n",
    "    # Second Dense layer with 8 units, ReLU activation, and L2 regularization\n",
    "    model = Dense(8, activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(0.001))(model)\n",
    "\n",
    "    # Output layer with 1 unit (binary classification) and Sigmoid activation\n",
    "    output = Dense(1, activation='sigmoid', name='output')(model)\n",
    "\n",
    "    # Compile the model\n",
    "    model = Model(inputs=[review], outputs=[output])\n",
    "\n",
    "    # Print a summary of the model's architecture\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a492c5f",
   "metadata": {},
   "source": [
    "## Initializing the Sentiment Analysis Model\n",
    "\n",
    "After defining our model architecture in the `LSTM_Glove_model` function, it's now time to initialize it using our data's vocabulary and the pre-trained embedding matrix.\n",
    "\n",
    "### Setting Vocabulary Size:\n",
    "We first determine the vocabulary size based on our dataset:\n",
    "```python\n",
    "max_vocabulary = len(tokenizer.word_index)\n",
    "```\n",
    "The `tokenizer.word_index` gives us the number of unique words present in our dataset.\n",
    "\n",
    "### Model Initialization:\n",
    "With the vocabulary size and pre-trained embedding matrix in hand, we can proceed to initialize our model:\n",
    "```python\n",
    "model = create_review_model(embedding_matrix, max_vocabulary)\n",
    "```\n",
    "At this point, the model will be ready, and a summary of its architecture will be printed, providing an overview of layers, output shapes, and the number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5nUEHzeqmCIx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nUEHzeqmCIx",
    "outputId": "ed987701-7e30-449e-de50-3420d9cf63e9"
   },
   "outputs": [],
   "source": [
    "max_vocabulary = len(tokenizer.word_index)\n",
    "model = LSTM_Glove_model(embedding_matrix, max_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e52df0",
   "metadata": {},
   "source": [
    "## Visualizing the Model Architecture\n",
    "\n",
    "To better understand and showcase the architecture of our model, visualizing its structure can be quite beneficial. This can also serve as documentation for future reference or for presenting the model's design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab34f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "collapsed": true,
    "id": "5bab34f8",
    "outputId": "f28811f9-8f0f-479e-d8cb-e9d641cde877"
   },
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "plot_model(model, to_file='model_results/LSTM_Glove_model_architecture_plot.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ed7944",
   "metadata": {
    "id": "c3ed7944"
   },
   "source": [
    "## Model Compilation and Training\n",
    "\n",
    "Before training our sentiment analysis model on the Amazon reviews, we need to specify certain parameters like the optimizer, loss function, and metrics. After the model is compiled, we proceed to train it using our training dataset.\n",
    "\n",
    "### Model Compilation:\n",
    "\n",
    "- **Optimizer:** `adam` \n",
    "  - The Adam optimizer is a popular choice in deep learning due to its efficient handling of sparse gradients and adaptive learning rates.\n",
    "  \n",
    "- **Loss:** `binary_crossentropy`\n",
    "  - Given that we're tackling a binary classification problem (positive or negative sentiment), the binary crossentropy loss function is suitable.\n",
    "  \n",
    "- **Metrics:** `accuracy`\n",
    "  - Accuracy metric provides a straightforward understanding of how well the model is performing by calculating the proportion of correctly classified reviews.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "```\n",
    "\n",
    "### Model Training:\n",
    "\n",
    "The actual learning happens during this phase:\n",
    "\n",
    "- **Training Data:** `(X_train, Y_train)`\n",
    "  \n",
    "- **Batch Size:** `64`\n",
    "  - This indicates the number of training examples used in each iteration to update the model's weights. \n",
    "  \n",
    "- **Epochs:** `20`\n",
    "  - The model will go through the entire training dataset 20 times. \n",
    "  \n",
    "- **Validation Data:** `(X_test, Y_test)`\n",
    "  - This provides a way to monitor the model's performance on unseen data after each epoch.\n",
    "  \n",
    "- **Verbose:** `1`\n",
    "  - Ensures that the training process displays logs for each epoch.\n",
    "\n",
    "```python\n",
    "history = model.fit(X_train, Y_train, batch_size = 64, epochs = 20, verbose = 1, validation_data = (X_test, Y_test))\n",
    "```\n",
    "\n",
    "By the end of this training phase, the model will have adjusted its weights based on the provided training data. The returned `history` object will contain details about the training and validation accuracy and loss across epochs, which can be useful for plotting and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XgRmZrZahT-9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgRmZrZahT-9",
    "outputId": "fb08c7c9-ce73-4636-8bbd-cfea663a1cb0"
   },
   "outputs": [],
   "source": [
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Compile and fit the model with the callback\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=64, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40oqaP9wFdUo",
   "metadata": {
    "id": "40oqaP9wFdUo"
   },
   "source": [
    "## Saving the Model\n",
    "\n",
    "After training, it's essential to save the trained model to reuse it later without having to retrain. Saving ensures that both the architecture and the learned weights are preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ec1d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "132ec1d6",
    "outputId": "0c25c769-a63f-4bec-8bf7-e2d9f5ecb1be"
   },
   "outputs": [],
   "source": [
    "model.save(\"model_results/LSTM_Glove_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O5KjpChnFpHo",
   "metadata": {
    "id": "O5KjpChnFpHo"
   },
   "source": [
    "LOADING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kaNUbs0UGz32",
   "metadata": {
    "id": "kaNUbs0UGz32"
   },
   "outputs": [],
   "source": [
    "path = \"model_results/LSTM_Glove_model.h5\"\n",
    "model = load_model(path, custom_objects={'Bidirectional': Bidirectional})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kaNEyQAqFtY-",
   "metadata": {
    "id": "kaNEyQAqFtY-"
   },
   "source": [
    "## Model Predictions and Evaluation\n",
    "\n",
    "Once the model has been trained, it's essential to use it to make predictions on unseen data and then evaluate how well it performed.\n",
    "\n",
    "### Making Predictions:\n",
    "\n",
    "Using the `predict` method of the trained model, we generate predicted values for the test set:\n",
    "\n",
    "```python\n",
    "preds = model.predict(X_test)\n",
    "```\n",
    "\n",
    "### Evaluation Results:\n",
    "\n",
    "After obtaining the predictions, we pass them to our `evaluate_model_performance` function, along with the true labels (`Y_test`), to get a suite of performance metrics:\n",
    "\n",
    "- **Accuracy Score:** \\(0.9030\\)\n",
    "  - Indicates that the model correctly predicted the sentiment of about 90.30% of the reviews in the test set.\n",
    "  \n",
    "- **F1 Score:** \\(0.9018\\)\n",
    "  - The harmonic mean of Precision and Recall, suggesting a good balance between false positives and false negatives.\n",
    "  \n",
    "- **ROC AUC Score:** \\(0.9628\\)\n",
    "  - Signifies that the model has a high capability to distinguish between positive and negative sentiments.\n",
    "  \n",
    "- **Precision:** \\(0.9095\\)\n",
    "  - Out of all the reviews predicted as positive, about 90.95% were actually positive.\n",
    "  \n",
    "- **Sensitivity:** \\(0.8943\\)\n",
    "  - Out of all the actual positive reviews, about 89.43% were correctly identified by the model.\n",
    "  \n",
    "- **Specificity:** \\(0.9116\\)\n",
    "  - Out of all the actual negative reviews, about 91.16% were correctly identified by the model.\n",
    "  \n",
    "- **Cross-Entropy Loss:** \\(0.3042\\)\n",
    "  - A lower value is better, and it indicates how well the probability predictions of the model align with the true labels.\n",
    "\n",
    "The provided metrics give a holistic view of the model's performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GUuEj5OPTyC_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUuEj5OPTyC_",
    "outputId": "24b2ca7a-9452-4d71-e1e3-cd776ab538c9"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "evaluate_model_performance(Y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d7547",
   "metadata": {},
   "source": [
    "## Plotting the Confusion Matrix\n",
    "\n",
    "With the `plot_confusion_matrix` function defined, we can now visualize the confusion matrix for the model predictions on our test set. This will give us a clearer understanding of where our model might be making mistakes.\n",
    "\n",
    "### Expected Output:\n",
    "\n",
    "The heatmap will show the actual counts of:\n",
    "- **True Positives (TP):** Reviews that were actually positive and were also predicted as positive.\n",
    "- **True Negatives (TN):** Reviews that were actually negative and were also predicted as negative.\n",
    "- **False Positives (FP):** Reviews that were actually negative but were predicted as positive.\n",
    "- **False Negatives (FN):** Reviews that were actually positive but were predicted as negative.\n",
    "\n",
    "By examining this matrix, we can gather insights into the type and frequency of errors made by our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd55a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = make_rounded_predictions(model, X_test)\n",
    "lstm_plot_confusion_matrix(predictions, Y_test, 'model_results/LSTM_Glove_model_confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c083a4d2",
   "metadata": {},
   "source": [
    "## Predicted vs. Actual Labels: Detailed Breakdown\n",
    "\n",
    "Following the execution of the `calculate_predicted_and_actual` function, here is the breakdown of our model's predictions compared to the actual numbers:\n",
    "\n",
    "### Predictions:\n",
    "- **Predicted 'Yes' (Positive Reviews):** 12,360\n",
    "  - This indicates the total number of reviews the model predicted to be positive.\n",
    "  \n",
    "- **Predicted 'No' (Negative Reviews):** 12,402\n",
    "  - This represents the total number of reviews the model predicted to be negative.\n",
    "\n",
    "### Actual Data:\n",
    "- **Actual Positive Reviews:** 12,132\n",
    "  - The test dataset had this many actual positive reviews.\n",
    "  \n",
    "- **Actual Negative Reviews:** 12,630\n",
    "  - The test dataset had this many actual negative reviews.\n",
    "\n",
    "### Insights:\n",
    "\n",
    "- The model predicted a slightly higher number of negative reviews (12,402) than positive ones (12,360). This is fairly balanced.\n",
    "  \n",
    "- Compared to the actual distribution in the test set, the model slightly overestimated the number of positive reviews and underestimated the number of negative reviews.\n",
    "\n",
    "- The difference in actual vs. predicted values for both positive and negative reviews is not drastic, indicating a relatively good performance of the model in terms of class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BlT8LSBBXmbs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BlT8LSBBXmbs",
    "outputId": "4be3abe8-5839-4c2c-a796-e628fcf5f3cb"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(predictions, Y_test)\n",
    "calculate_predicted_and_actual(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf2405",
   "metadata": {},
   "source": [
    "## Interpretation of the Training and Validation Loss Plot:\n",
    "**Function Description:**  \n",
    "The `plot_loss` function is used to visualize the evolution of loss values during the training process. It plots both the training loss and the validation loss against the number of epochs, allowing us to observe how the model's performance changes over time.\n",
    "\n",
    "**1. Convergence Point at Epoch 5:** \n",
    "The fact that the training and validation loss lines touched at epoch 5 indicates that up to this point, the model was generalizing well, and the losses were converging.\n",
    "\n",
    "**2. Signs of Overfitting:** \n",
    "Post epoch 5, the continuous decrease in training loss accompanied by a stagnant validation loss is a typical sign of overfitting. This means that while the model is getting better and better at fitting the training data (hence the decreasing training loss), its performance on unseen data (validation set) is not improving, implying that the model might be memorizing the training data.\n",
    "\n",
    "**3. Early Stopping is Beneficial:** \n",
    "The early stopping callback stopping the training at epoch 8 was apt. This mechanism prevents the model from overfitting further by halting the training when the validation performance fails to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EtItrL4OImUt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "EtItrL4OImUt",
    "outputId": "78025b94-472c-4267-8e01-3f8dfa542bdc"
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss using the defined function and save it\n",
    "plot_loss(history, 'model_results/LSTM_Glove_loss_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f6432",
   "metadata": {},
   "source": [
    "# BERT MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7556101d",
   "metadata": {},
   "source": [
    "## Sampling the Dataset\n",
    "\n",
    "Our Amazon reviews dataset contains over 82,000 entries. To make possible to compile and train with our available computing power, we will down-sample the dataset to 10,000.\n",
    "\n",
    "By using this sampled dataset, we can reduce the computational cost and time required for training and testing our model. However, it's essential to remember that downsampling might lead to loss of information, and the model might not perform as well as if trained on the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QMtX4V8igNv_",
   "metadata": {
    "id": "QMtX4V8igNv_"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data_for_modelling/ready_data_for_modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dxD0LOcCg2lO",
   "metadata": {
    "id": "dxD0LOcCg2lO"
   },
   "outputs": [],
   "source": [
    "# We run only 10,000 out of over 82,000 because of the limited computing power\n",
    "df = df.sample(n=10000)  # To take a random sample of 10000 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef2da14",
   "metadata": {},
   "source": [
    "## Splitting Data for Amazon Sentiment Analysis\n",
    "\n",
    "When conducting sentiment analysis on Amazon reviews, it's imperative to partition the data into separate training and test sets. The training set is utilized to train the model, while the test set serves to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wOU3knWGLa53",
   "metadata": {
    "id": "wOU3knWGLa53"
   },
   "outputs": [],
   "source": [
    "# Execute the split_data function to get the training and test sets.\n",
    "train_texts, test_texts, train_labels, test_labels = split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a39b8dc",
   "metadata": {},
   "source": [
    "## Tokenization with BERT for Amazon Sentiment Analysis\n",
    "\n",
    "For deep learning models, especially the BERT model, raw text data needs to be converted into a format that the model can understand. This process is known as tokenization. BERT requires a specialized tokenizer because it tokenizes text in a way that's compatible with its pre-trained vocabulary.\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "```python\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "```\n",
    "\n",
    "- **`BertTokenizer.from_pretrained('bert-base-uncased')`**: This initializes the tokenizer based on the BERT base model that's been trained on uncased (or lowercase) text. \"Uncased\" means that the pre-training was done on lowercase text, and the model does not differentiate between uppercase and lowercase letters.\n",
    "\n",
    "  - `'bert-base-uncased'` is the identifier for the base version of the BERT model, trained on English text in lowercase. It's one of the most widely used versions of BERT due to its balance between size (smaller and faster) and performance.\n",
    "\n",
    "- **`do_lower_case=True`**: This argument ensures that all tokens produced by the tokenizer are in lowercase, aligning with the 'uncased' nature of our chosen BERT model.\n",
    "\n",
    "With the tokenizer loaded, we can now process the Amazon reviews to transform them into tokenized sequences, making them ready for training and evaluation in the BERT model for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OjBbxdZmLcd9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "8cec5430bea24ba382688624752a8a8b",
      "c629dabb10f24551b0e9f9f9535d9a25",
      "311f5fc487134928ad2ada4be2da0eac",
      "0623245b051d4833bfbf9a2324899e65",
      "7ec83756066a4d278f8ac0c7d1a600a8",
      "ce231f92d3be44218254bf3db1726d99",
      "13debca6fbbb4cb4b6d029dca0de29b1",
      "df0333fed8184483a82ed3e00b26f768",
      "f6ab8a56289f4f49a2dd608d0ebc14cd",
      "ecec09bb87fd4f75b5031dd2028ce50a",
      "7b04fcb689124aae8753a513219b9323",
      "5263d75c7946445e97087d9e35bbd933",
      "9010309ca39e4da1bc867bb4f7b46af2",
      "e186f5c3c5024deca8464db685b242e3",
      "80a70b28278046edbc7f4705616d73d9",
      "0e2ecd1483c1448080075aab85378e5d",
      "04f8f7ea73e44685860d62501b92332a",
      "ebd5855e5fea42e28501d144ee2f4332",
      "edf5f54b06b14d7ca4236e3eb34a6cc8",
      "3faa073813c54cb6924162d7cf77d7bb",
      "4e3cb5693c714bb3bff4b1d57c84da4c",
      "e108055463b2416ab33e2cca8e0f68e0",
      "c8f95a31631947ec82bf88d74ac93a80",
      "d34f3737cecc49dbb1a115609f22cc47",
      "ea91b7037dff4e18a764e2eef56a44bd",
      "c0293354b360432bbaa50c16475c4928",
      "8ce5f2da8c154eb0b3431bd008e6843b",
      "f2698616407a4a36be8831094e80a3ce",
      "32043e3de729461abc11a1b6c6e9c241",
      "1ed72c87fc3d4748a59542afdec94e37",
      "aeb516d5f01c4bf0a93641713180d7ea",
      "42e87c80e40844bcaef582e8842d9bd5",
      "fa918b1ad4534701a7d2e1a3f9c7f564"
     ]
    },
    "id": "OjBbxdZmLcd9",
    "outputId": "b771e1c1-b6ab-4c5d-8f53-57fc35f16218"
   },
   "outputs": [],
   "source": [
    "# Load the uncased BERT tokenizer, converting all tokens to lowercase.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a3b3f9",
   "metadata": {},
   "source": [
    "## Tokenizing Amazon Reviews for Sentiment Analysis with BERT\n",
    "\n",
    "To prepare the Amazon reviews for sentiment analysis with the BERT model, we need to tokenize the text. BERT tokenization is a bit more involved than typical tokenization, and it involves creating \"input IDs\" and \"attention masks.\"\n",
    "\n",
    "**Purpose**: This function processes raw review texts into a format suitable for the BERT model.\n",
    "\n",
    "After executing these lines of code, the training and test Amazon reviews are transformed into tokenized sequences and attention masks. These can be fed into the BERT model for sentiment analysis training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P0IKWOx5Le-v",
   "metadata": {
    "id": "P0IKWOx5Le-v"
   },
   "outputs": [],
   "source": [
    "# Tokenize the training and test texts\n",
    "train_input_ids, train_attention_masks = tokenize_texts(train_texts)\n",
    "test_input_ids, test_attention_masks = tokenize_texts(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ee1e5",
   "metadata": {},
   "source": [
    "## Creating TensorFlow Datasets for Model Training and Evaluation\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "```python\n",
    "train_data = get_dataset(train_input_ids, train_attention_masks, train_labels).shuffle(100).batch(64).repeat(2)\n",
    "```\n",
    "\n",
    "- **`get_dataset(...)`**: Using the previously defined `get_dataset` function, we convert our tokenized training reviews and their labels into a TensorFlow dataset.\n",
    "\n",
    "- **`.shuffle(100)`**: Shuffling helps prevent patterns during training and makes the model more robust. `100` is the size of the shuffle buffer, which determines how many samples from the dataset should be loaded and then a random sample will be chosen from those to ensure randomness. A larger buffer size will have better shuffling at the expense of memory.\n",
    "\n",
    "- **`.batch(64)`**: Batching groups multiple samples together to process in parallel, speeding up training. Here, we've chosen a batch size of 64, meaning the model will process 64 reviews simultaneously in each step. In our case, we cannot choose higher batch size since we do not have enough computing power.\n",
    "\n",
    "- **`.repeat(2)`**: The dataset will be repeated twice. This is useful for training over multiple epochs. Essentially, our model will see each review twice during training.\n",
    "\n",
    "```python\n",
    "test_data = get_dataset(test_input_ids, test_attention_masks, test_labels).batch(64)\n",
    "```\n",
    "\n",
    "- Here, we're doing the same thing as before but for our test data. We only need to batch the test data without the need for shuffling or repeating. This dataset will be used for evaluating the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ym1tNXqLhhZ",
   "metadata": {
    "id": "8ym1tNXqLhhZ"
   },
   "outputs": [],
   "source": [
    "# Convert tokenized training texts and labels into a dataset, then shuffle, batch, and repeat\n",
    "train_data = get_dataset(train_input_ids, train_attention_masks, train_labels).shuffle(100).batch(64).repeat(2)\n",
    "\n",
    "# Convert tokenized test texts and labels into a dataset, then batch\n",
    "test_data = get_dataset(test_input_ids, test_attention_masks, test_labels).batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a7d954",
   "metadata": {},
   "source": [
    "## Constructing a Customized BERT Model for Amazon Sentiment Analysis\n",
    "\n",
    "### Here, we try to dive as deep as possible!\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is a state-of-the-art model for a variety of natural language processing tasks. In this section, we're customizing BERT for sentiment analysis on Amazon reviews, introducing regularization and dropout to enhance performance and prevent overfitting.\n",
    "\n",
    "### Function Explanation: `get_model`\n",
    "\n",
    "```python\n",
    "def get_model():\n",
    "```\n",
    "\n",
    "**Purpose**: This function initializes the BERT model for sequence classification, freezes certain layers for fine-tuning, and introduces a modified classifier with dropout and regularization.\n",
    "\n",
    "**Returns**:\n",
    "- **`model (TFBertForSequenceClassification)`**: The enhanced BERT model ready for sequence classification tasks, in our case, sentiment analysis.\n",
    "\n",
    "Inside the function:\n",
    "\n",
    "```python\n",
    "    model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "```\n",
    "\n",
    "- **`TFBertForSequenceClassification.from_pretrained`**: This loads the pre-trained BERT model tailored for sequence classification tasks. The \"bert-base-uncased\" version indicates that the model uses the base-sized BERT with all tokens converted to lowercase.\n",
    "\n",
    "```python\n",
    "    for layer in model.bert.encoder.layer[:9]:\n",
    "        layer.trainable = False\n",
    "```\n",
    "\n",
    "- Here, we're freezing (making non-trainable) the first 9 layers of the BERT model. This is a form of transfer learning. Instead of retraining the entire model from scratch, we'll leverage the existing knowledge BERT has from pre-training and only fine-tune the later layers on our specific Amazon review dataset.\n",
    "\n",
    "```python\n",
    "    classifier_input = tf.keras.Input(...)\n",
    "    x = tf.keras.layers.Dropout(0.5)(classifier_input)\n",
    "    classifier_output = tf.keras.layers.Dense(...)(x)\n",
    "    regularized_classifier_model = tf.keras.Model(inputs=classifier_input, outputs=classifier_output)\n",
    "```\n",
    "\n",
    "- We're creating a new classifier to replace the default one in BERT. Key modifications include:\n",
    "  - **`Dropout`**: Adds a dropout layer with a rate of 0.5, meaning approximately half of the inputs will be randomly set to zero during training. Dropout is a regularization technique to reduce the risk of overfitting. When building the model, it faced several times overfitting so we kept increasing dropout rate untill 0.5.\n",
    "  - **`Dense` layer with L2 regularization**: Introduces a penalty on the layer's weights. Regularization can prevent the model from fitting too closely to the training data, making it generalize better to unseen data.\n",
    "\n",
    "```python\n",
    "    model.classifier = regularized_classifier_model\n",
    "```\n",
    "\n",
    "- This line replaces BERT's original classifier with our newly defined regularized classifier.\n",
    "\n",
    "In conclusion, the `get_model` function provides an enhanced version of the BERT model for sentiment analysis on Amazon reviews. By freezing certain layers, introducing dropout, and adding regularization, we're better equipping the model to generalize to new, unseen reviews while leveraging the powerful features of BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EeqpFekVLilI",
   "metadata": {
    "id": "EeqpFekVLilI"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"\n",
    "    Load the BERT model, freeze specified layers, and modify the classifier with regularization and dropout.\n",
    "\n",
    "    Returns:\n",
    "    - model (TFBertForSequenceClassification): The modified BERT model for sequence classification.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the BERT model for sequence classification\n",
    "    model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    # Make the first 9 layers of the BERT model non-trainable\n",
    "    for layer in model.bert.encoder.layer[:9]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Define a new classifier layer with dropout and L2 regularization\n",
    "    classifier_input = tf.keras.Input(shape=(model.config.hidden_size,), dtype=tf.float32, name=\"inputs\")\n",
    "    x = tf.keras.layers.Dropout(0.5)(classifier_input)\n",
    "    classifier_output = tf.keras.layers.Dense(\n",
    "        model.config.num_labels,\n",
    "        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=model.config.initializer_range),\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.01)\n",
    "    )(x)\n",
    "\n",
    "    # Construct the new classifier model\n",
    "    regularized_classifier_model = tf.keras.Model(inputs=classifier_input, outputs=classifier_output)\n",
    "\n",
    "    # Integrate the new classifier into the BERT model\n",
    "    model.classifier = regularized_classifier_model\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce3fe6",
   "metadata": {},
   "source": [
    "## Initializing the Customized BERT Model for Amazon Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4HzptJpsLkAD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "e4cc3f4da40c4d3dadc7a416af0912ba",
      "15b5eb6a4a3943a1abb41641603a1dbf",
      "a181bf4520e1467f8efc5a03009baa51",
      "40b2adfee5d44532bd3ad157bd73d31a",
      "c14dd69d9608443a96a748cf6b04863c",
      "271c7bbc916541008cbad216146832f1",
      "fc00f284d9d24315a632ef2f08070829",
      "387465de81a745bcad5e934e3c046802",
      "f5b1e108136545399b796dd0f552b8ea",
      "22857b84650d484d9b3a2794c13ba41a",
      "74823fadbb084ba5a4b86dacffcfd34c"
     ]
    },
    "id": "4HzptJpsLkAD",
    "outputId": "848f4d31-3c08-4d9e-b57c-409a8a11873b"
   },
   "outputs": [],
   "source": [
    "# Instantiate the modified BERT model\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e859bfd",
   "metadata": {},
   "source": [
    "## Fine-Tuning the BERT Model for Amazon Sentiment Analysis\n",
    "\n",
    "In this phase, we will compile and train our custom BERT model on the Amazon reviews dataset. Training involves adjusting the model's weights based on our data so that it can accurately perform sentiment analysis on Amazon reviews.\n",
    "\n",
    "### Function Explanation: `compile_and_train`\n",
    "\n",
    "```python\n",
    "def compile_and_train(model, train_data, test_data):\n",
    "```\n",
    "\n",
    "**Purpose**: To compile, train, and evaluate the BERT model using the provided training and test datasets.\n",
    "\n",
    "Inside the function:\n",
    "```python\n",
    "initial_learning_rate = 3e-6\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9,\n",
    "        staircase=True)\n",
    "```\n",
    "- **Learning Rate Scheduling**: The learning rate determines how drastically the model's weights are adjusted during training. Starting with an initial rate of `3e-6`, the learning rate is scheduled to decrease (decay) over time. Specifically, every 10,000 steps, the learning rate is multiplied by a factor of 0.9. This decay helps stabilize training as the model approaches convergence.\n",
    "```python\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "```\n",
    "- **Adam Optimizer**: Adam is a popular optimization algorithm that combines the best properties of the AdaGrad and RMSprop algorithms. It's widely used for deep learning models. Here, it's configured with our learning rate schedule.\n",
    "```python\n",
    "model.compile(...)\n",
    "```\n",
    "- **Compiling the Model**: This step is about configuring the model for training. The following are set:\n",
    "  - **Loss Function**: `SparseCategoricalCrossentropy(from_logits=True)`. Given our task is classification, this loss function computes the crossentropy loss between the labels and the predictions. The `from_logits=True` flag indicates that the model's outputs are not probabilities.\n",
    "  - **Metrics**: Accuracy, to determine the proportion of correctly predicted classifications.\n",
    "```python\n",
    "early_stopping = EarlyStopping(...)\n",
    "```\n",
    "- **Early Stopping**: It's a regularization method that stops the training process once the model's performance starts degrading on a held-out validation dataset. This mechanism helps in preventing overfitting and saves computational resources. Here, we're monitoring the validation loss (`val_loss`), and if it doesn't improve for 2 consecutive epochs (`patience=2`), training will stop and revert back to the best weights.\n",
    "```python\n",
    "history = model.fit(train_data, epochs=20, verbose=1, validation_data=test_data, callbacks=[early_stopping])\n",
    "```\n",
    "- **Training the Model**: The BERT model is trained using the `fit` method. We use the `train_data` for training and `test_data` for validation. If the validation performance doesn't improve for two consecutive epochs, thanks to our early stopping callback, training will halt.\n",
    "\n",
    "In summary, the `compile_and_train` function sets the stage for fine-tuning our BERT model on Amazon reviews for sentiment analysis. By employing learning rate decay, the Adam optimizer, and early stopping, we ensure that the model learns effectively without overfitting. Once the model is trained, it's ready to make predictions on new Amazon reviews and classify their sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ARhvbfWfLlPt",
   "metadata": {
    "id": "ARhvbfWfLlPt"
   },
   "outputs": [],
   "source": [
    "def compile_and_train(model, train_data, test_data):\n",
    "    \"\"\"\n",
    "    Compile, train, and evaluate the BERT model using given data.\n",
    "\n",
    "    Parameters:\n",
    "    - model (TFBertForSequenceClassification): The BERT model for sequence classification.\n",
    "    - train_data (tf.data.Dataset): The training dataset.\n",
    "    - test_data (tf.data.Dataset): The validation/test dataset.\n",
    "\n",
    "    Returns:\n",
    "    - model (TFBertForSequenceClassification): The trained BERT model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define learning rate and decay for optimizer\n",
    "    initial_learning_rate = 3e-6\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps=10000,  # Decrease learning rate every 10,000 steps\n",
    "        decay_rate=0.9,\n",
    "        staircase=True)\n",
    "\n",
    "    # Use the Adam optimizer with learning rate decay\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    # Compile the model with sparse categorical crossentropy and accuracy metric\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "\n",
    "    # Set early stopping criteria to prevent overfitting\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',  # Monitor validation loss for early stopping\n",
    "        patience=2,  # Number of epochs with no improvement to trigger early stopping\n",
    "        verbose=1,\n",
    "        restore_best_weights=True)  # Restore model weights from the best epoch\n",
    "\n",
    "    # Train the model using the training data and validate using test data\n",
    "    history = model.fit(train_data, epochs=20, verbose=1, validation_data=test_data, callbacks=[early_stopping])\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739c8047",
   "metadata": {},
   "source": [
    "## BERT Model Training\n",
    "\n",
    "Let's deep dive into the results of the training process for our fine-tuned BERT model on the Amazon reviews dataset:\n",
    "\n",
    "### Training Summary:\n",
    "\n",
    "1. **Total Epochs**: `14 out of 20`\n",
    "   - The model training was early-stopped at the 14th epoch, indicating that further training didn't improve the validation loss.\n",
    "\n",
    "2. **Batch Size**: `64`\n",
    "   - Each batch contains 64 reviews that the model processes simultaneously.\n",
    "\n",
    "### Model Performance Over Epochs:\n",
    "\n",
    "- **Initial Epoch (Epoch 1)**:\n",
    "  - Training Loss: `0.6373`, Training Accuracy: `64.24%`\n",
    "  - Validation Loss: `0.4632`, Validation Accuracy: `82.73%`\n",
    "\n",
    "- **Best Epoch (Epoch 12)**:\n",
    "  - Training Loss: `0.1774`, Training Accuracy: `93.46%`\n",
    "  - Validation Loss: `0.2599`, Validation Accuracy: `90.17%`\n",
    "\n",
    "- **Last Epoch (Epoch 14)**:\n",
    "  - Training Loss: `0.1602`, Training Accuracy: `94.21%`\n",
    "  - Validation Loss: `0.2697`, Validation Accuracy: `90.17%`\n",
    "\n",
    "### Observations:\n",
    "\n",
    "1. **Learning Progress**: The training accuracy improved significantly from the initial 64.24% in the first epoch to 94.21% in the 14th epoch. The model has learned well from the training data, as evident from the accuracy improvement.\n",
    "\n",
    "2. **Overfitting and Early Stopping**: The early stopping was triggered at epoch 14, restoring the weights from epoch 12, which had the best validation loss. This ensures that the model doesn't overfit to the training data and can generalize well on unseen data.\n",
    "\n",
    "3. **Validation Results**: The validation accuracy was consistently higher after the initial epochs, reaching its peak at `90.17%` in epoch 12. This shows that our model is effective in sentiment prediction for unseen Amazon reviews.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "The fine-tuning process of the BERT model has been successful. With an impressive accuracy on the validation set, we can conclude that the model is likely to perform well in real-world scenarios when given new Amazon reviews for sentiment prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Guk9YZjgLl3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Guk9YZjgLl3a",
    "outputId": "379a347e-4d43-4b14-f7af-3d214929af52"
   },
   "outputs": [],
   "source": [
    "# Compile, train, and evaluate the BERT model using the provided data\n",
    "model, history = compile_and_train(model, train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195c8229",
   "metadata": {},
   "source": [
    "## Model Evaluation Results on the test data\n",
    "\n",
    "After evaluating our fine-tuned BERT model on the test dataset, we've obtained the following results:\n",
    "\n",
    "### Model Performance Metrics:\n",
    "\n",
    "**1. Loss**: `0.2599`\n",
    "   - This value represents the model's error on the test set. In other words, it's a measure of how well the model's predictions match the true ratings in the test data. A lower loss value is generally better, indicating that the model's predictions are closer to the true values.\n",
    "\n",
    "**2. Accuracy**: `90.17%`\n",
    "   - This is a measure of how many of the test reviews the model correctly classified. An accuracy of 90.17% means the model correctly predicted the sentiment of approximately 9 out of every 10 reviews in the test set.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "The model exhibits a high accuracy on the test set, suggesting that it is effective at performing sentiment analysis on Amazon reviews. An accuracy of over 90% indicates that our fine-tuning process with the BERT model has been successful in capturing the nuances of sentiment in the Amazon reviews dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h7Sb5c8DLnPn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7Sb5c8DLnPn",
    "outputId": "37a0dc1f-1446-44e0-85d7-7cd42aadf2fc"
   },
   "outputs": [],
   "source": [
    "# Evaluate on the Test Set\n",
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bd5d59",
   "metadata": {},
   "source": [
    "## Saving the Fine-tuned BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KprLV1eCLpKy",
   "metadata": {
    "id": "KprLV1eCLpKy"
   },
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_path = \"model_results/BERT_model\"\n",
    "model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8BiD4p3Lqt8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8BiD4p3Lqt8",
    "outputId": "57422442-83b0-449b-84f5-3436676c87ac",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model_path = \"model_results/BERT_model\"\n",
    "loaded_model = TFBertForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45116de",
   "metadata": {},
   "source": [
    "## Model Evaluation Insights: Sentiment Analysis with BERT on Amazon Reviews\n",
    "\n",
    "Following the evaluation of our trained BERT model on the test data, let's dive deep into understanding the results.\n",
    "\n",
    "### **1. Accuracy: 0.9017**\n",
    "\n",
    "An accuracy of **~90.17%** is quite high, suggesting that the model has learned a significant amount from the training data and can generalize well to unseen samples.\n",
    "\n",
    "### **2. F1 Score: 0.9015**\n",
    "\n",
    "An F1 score of **~90.15%** is very good, especially for NLP tasks such as sentiment analysis, where context matters. This suggests that our model has both good precision and recall.\n",
    "\n",
    "### **3. ROC AUC Score: 0.9666**\n",
    "\n",
    "ROC AUC (Receiver Operating Characteristic Area Under Curve) measures the area under the ROC curve, which is a plot of the true positive rate versus the false positive rate. An ROC AUC of **~96.66%** indicates a very good ability of the model to distinguish between the positive and negative classes. This score is especially crucial for imbalanced datasets.\n",
    "\n",
    "### **4. Precision: 0.9012 & Recall: 0.9020**\n",
    "\n",
    "- **Precision** denotes how many of the positive classifications were actually correct. A precision of **~90.12%** indicates a high rate of relevant results.\n",
    "  \n",
    "- **Recall** refers to the percentage of total relevant results correctly classified by the algorithm. A recall of **~90.20%** is commendable, showing the model has a good hit rate.\n",
    "\n",
    "### **5. Sensitivity: 0.8951 & Specificity: 0.9090**\n",
    "\n",
    "These are metrics specific to binary classification:\n",
    "- **Sensitivity (True Positive Rate)** of **~89.51%** suggests the model correctly identifies positive samples a majority of the time.\n",
    "  \n",
    "- **Specificity (True Negative Rate)** of **~90.90%** shows the model's effectiveness in correctly identifying negative samples.\n",
    "\n",
    "### **6. Cross-Entropy Loss: 0.2553**\n",
    "\n",
    "A lower value is better, suggesting that the predicted probabilities align closely with the actual labels. The value of **0.2553** is relatively low, indicating that the model's predictions are in good alignment with the true labels.\n",
    "\n",
    "### **Final Thoughts**:\n",
    "\n",
    "The BERT model's performance on the sentiment analysis task for Amazon reviews is commendable. With scores consistently around the 90% mark across most metrics, it demonstrates the power of transformer-based BERT model for sentiment analysis for Amazon reviews in understanding and classifying textual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ctiBA1mcLtFt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ctiBA1mcLtFt",
    "outputId": "1d871154-2507-40b9-e4a9-cfdc9f4e460d"
   },
   "outputs": [],
   "source": [
    "evaluate_metrics(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e42026",
   "metadata": {},
   "source": [
    "## Model Evaluation Insights: Sentiment Analysis with BERT on Amazon Reviews\n",
    "\n",
    "Following the evaluation of our trained BERT model on the test data, let's dive deep into understanding the results.\n",
    "\n",
    "### **1. Accuracy: 0.9017**\n",
    "\n",
    "An accuracy of **~90.17%** is quite high, suggesting that the model has learned a significant amount from the training data and can generalize well to unseen samples.\n",
    "\n",
    "### **2. F1 Score: 0.9015**\n",
    "\n",
    "An F1 score of **~90.15%** is very good, especially for NLP tasks such as sentiment analysis, where context matters. This suggests that our model has both good precision and recall.\n",
    "\n",
    "### **3. ROC AUC Score: 0.9666**\n",
    "\n",
    "ROC AUC (Receiver Operating Characteristic Area Under Curve) measures the area under the ROC curve, which is a plot of the true positive rate versus the false positive rate. An ROC AUC of **~96.66%** indicates a very good ability of the model to distinguish between the positive and negative classes. This score is especially crucial for imbalanced datasets.\n",
    "\n",
    "### **4. Precision: 0.9012 & Recall: 0.9020**\n",
    "\n",
    "- **Precision** denotes how many of the positive classifications were actually correct. A precision of **~90.12%** indicates a high rate of relevant results.\n",
    "  \n",
    "- **Recall** refers to the percentage of total relevant results correctly classified by the algorithm. A recall of **~90.20%** is commendable, showing the model has a good hit rate.\n",
    "\n",
    "### **5. Sensitivity: 0.8951 & Specificity: 0.9090**\n",
    "\n",
    "These are metrics specific to binary classification:\n",
    "- **Sensitivity (True Positive Rate)** of **~89.51%** suggests the model correctly identifies positive samples a majority of the time.\n",
    "  \n",
    "- **Specificity (True Negative Rate)** of **~90.90%** shows the model's effectiveness in correctly identifying negative samples.\n",
    "\n",
    "### **6. Cross-Entropy Loss: 0.2553**\n",
    "\n",
    "A lower value is better, suggesting that the predicted probabilities align closely with the actual labels. The value of **0.2553** is relatively low, indicating that the model's predictions are in good alignment with the true labels.\n",
    "\n",
    "### **Final Thoughts**:\n",
    "\n",
    "The BERT model's performance on the sentiment analysis task for Amazon reviews is commendable. With scores consistently around the 90% mark across most metrics, it demonstrates the power of transformer-based BERT model for sentiment analysis for Amazon reviews in understanding and classifying textual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nyXqjdN7Lyb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "id": "nyXqjdN7Lyb8",
    "outputId": "7e9e6298-8fd2-47ba-b2b3-3b0237fca724"
   },
   "outputs": [],
   "source": [
    "# Plotting confusion matrix for BERT model\n",
    "plot_confusion_matrix(model, test_input_ids, test_attention_masks, test_labels, save_path='model_results/BERT_model_confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8176c6dc",
   "metadata": {},
   "source": [
    "## BERT Model Training & Validation Loss Analysis for Amazon Reviews Sentiment\n",
    "\n",
    "- **Initial Losses:** Training loss started over 0.6 and decreased to below 0.2 by epoch 12. Validation loss began under 0.5 and approached 0.3 by epoch 12.\n",
    "  \n",
    "- **Loss Convergence:** Around epochs 4 and 5, training and validation losses intersected, which can be a balance point in learning. It's a juncture to monitor for potential overfitting.\n",
    "\n",
    "Key Takeaway: The consistent reduction in loss indicates BERT's effective learning on the Amazon reviews sentiment analysis task, but monitoring for overfitting is essential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95ueKk-HZk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "9b95ueKk-HZk",
    "outputId": "36d9001f-ad9d-4cd3-cf55-7ffe5b8c5871"
   },
   "outputs": [],
   "source": [
    "# Call the function\n",
    "plot_and_save_loss(history, 'model_results/BERT_training_validation_loss.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04f8f7ea73e44685860d62501b92332a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0623245b051d4833bfbf9a2324899e65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecec09bb87fd4f75b5031dd2028ce50a",
      "placeholder": "",
      "style": "IPY_MODEL_7b04fcb689124aae8753a513219b9323",
      "value": " 232k/232k [00:00&lt;00:00, 1.72MB/s]"
     }
    },
    "0e2ecd1483c1448080075aab85378e5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13debca6fbbb4cb4b6d029dca0de29b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "15b5eb6a4a3943a1abb41641603a1dbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_271c7bbc916541008cbad216146832f1",
      "placeholder": "",
      "style": "IPY_MODEL_fc00f284d9d24315a632ef2f08070829",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "1ed72c87fc3d4748a59542afdec94e37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22857b84650d484d9b3a2794c13ba41a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "271c7bbc916541008cbad216146832f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "311f5fc487134928ad2ada4be2da0eac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df0333fed8184483a82ed3e00b26f768",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6ab8a56289f4f49a2dd608d0ebc14cd",
      "value": 231508
     }
    },
    "32043e3de729461abc11a1b6c6e9c241": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "387465de81a745bcad5e934e3c046802": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3faa073813c54cb6924162d7cf77d7bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "40b2adfee5d44532bd3ad157bd73d31a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22857b84650d484d9b3a2794c13ba41a",
      "placeholder": "",
      "style": "IPY_MODEL_74823fadbb084ba5a4b86dacffcfd34c",
      "value": " 440M/440M [00:02&lt;00:00, 164MB/s]"
     }
    },
    "42e87c80e40844bcaef582e8842d9bd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e3cb5693c714bb3bff4b1d57c84da4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5263d75c7946445e97087d9e35bbd933": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9010309ca39e4da1bc867bb4f7b46af2",
       "IPY_MODEL_e186f5c3c5024deca8464db685b242e3",
       "IPY_MODEL_80a70b28278046edbc7f4705616d73d9"
      ],
      "layout": "IPY_MODEL_0e2ecd1483c1448080075aab85378e5d"
     }
    },
    "74823fadbb084ba5a4b86dacffcfd34c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b04fcb689124aae8753a513219b9323": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ec83756066a4d278f8ac0c7d1a600a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80a70b28278046edbc7f4705616d73d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e3cb5693c714bb3bff4b1d57c84da4c",
      "placeholder": "",
      "style": "IPY_MODEL_e108055463b2416ab33e2cca8e0f68e0",
      "value": " 28.0/28.0 [00:00&lt;00:00, 524B/s]"
     }
    },
    "8ce5f2da8c154eb0b3431bd008e6843b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cec5430bea24ba382688624752a8a8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c629dabb10f24551b0e9f9f9535d9a25",
       "IPY_MODEL_311f5fc487134928ad2ada4be2da0eac",
       "IPY_MODEL_0623245b051d4833bfbf9a2324899e65"
      ],
      "layout": "IPY_MODEL_7ec83756066a4d278f8ac0c7d1a600a8"
     }
    },
    "9010309ca39e4da1bc867bb4f7b46af2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04f8f7ea73e44685860d62501b92332a",
      "placeholder": "",
      "style": "IPY_MODEL_ebd5855e5fea42e28501d144ee2f4332",
      "value": "Downloading ()okenizer_config.json: 100%"
     }
    },
    "a181bf4520e1467f8efc5a03009baa51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_387465de81a745bcad5e934e3c046802",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f5b1e108136545399b796dd0f552b8ea",
      "value": 440449768
     }
    },
    "aeb516d5f01c4bf0a93641713180d7ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c0293354b360432bbaa50c16475c4928": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42e87c80e40844bcaef582e8842d9bd5",
      "placeholder": "",
      "style": "IPY_MODEL_fa918b1ad4534701a7d2e1a3f9c7f564",
      "value": " 570/570 [00:00&lt;00:00, 8.90kB/s]"
     }
    },
    "c14dd69d9608443a96a748cf6b04863c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c629dabb10f24551b0e9f9f9535d9a25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce231f92d3be44218254bf3db1726d99",
      "placeholder": "",
      "style": "IPY_MODEL_13debca6fbbb4cb4b6d029dca0de29b1",
      "value": "Downloading ()solve/main/vocab.txt: 100%"
     }
    },
    "c8f95a31631947ec82bf88d74ac93a80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d34f3737cecc49dbb1a115609f22cc47",
       "IPY_MODEL_ea91b7037dff4e18a764e2eef56a44bd",
       "IPY_MODEL_c0293354b360432bbaa50c16475c4928"
      ],
      "layout": "IPY_MODEL_8ce5f2da8c154eb0b3431bd008e6843b"
     }
    },
    "ce231f92d3be44218254bf3db1726d99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d34f3737cecc49dbb1a115609f22cc47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2698616407a4a36be8831094e80a3ce",
      "placeholder": "",
      "style": "IPY_MODEL_32043e3de729461abc11a1b6c6e9c241",
      "value": "Downloading ()lve/main/config.json: 100%"
     }
    },
    "df0333fed8184483a82ed3e00b26f768": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e108055463b2416ab33e2cca8e0f68e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e186f5c3c5024deca8464db685b242e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edf5f54b06b14d7ca4236e3eb34a6cc8",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3faa073813c54cb6924162d7cf77d7bb",
      "value": 28
     }
    },
    "e4cc3f4da40c4d3dadc7a416af0912ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_15b5eb6a4a3943a1abb41641603a1dbf",
       "IPY_MODEL_a181bf4520e1467f8efc5a03009baa51",
       "IPY_MODEL_40b2adfee5d44532bd3ad157bd73d31a"
      ],
      "layout": "IPY_MODEL_c14dd69d9608443a96a748cf6b04863c"
     }
    },
    "ea91b7037dff4e18a764e2eef56a44bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ed72c87fc3d4748a59542afdec94e37",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aeb516d5f01c4bf0a93641713180d7ea",
      "value": 570
     }
    },
    "ebd5855e5fea42e28501d144ee2f4332": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecec09bb87fd4f75b5031dd2028ce50a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edf5f54b06b14d7ca4236e3eb34a6cc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2698616407a4a36be8831094e80a3ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5b1e108136545399b796dd0f552b8ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f6ab8a56289f4f49a2dd608d0ebc14cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa918b1ad4534701a7d2e1a3f9c7f564": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc00f284d9d24315a632ef2f08070829": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
